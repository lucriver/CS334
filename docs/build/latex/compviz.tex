%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}


\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}


        \usepackage{listings}
        \lstset{ 
            language=Python,                 % the language of the code
            title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
        }
    

\title{Comp Viz}
\date{Nov 29, 2022}
\release{1.0.0}
\author{Lucas Hirt}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Comp Viz Summary}
\label{\detokenize{summary:comp-viz-summary}}\label{\detokenize{summary::doc}}
\sphinxAtStartPar
Comp Viz is a computer vision oriented package that aims to allow those unfamiliar with the subject to
explore and experiment with various computer vision related tasks like object detection, image segmentation,
classification, and more.

\sphinxAtStartPar
Comp Viz is built using MXNet’s gluoncv API. Comp Viz aims to provide a simple and intuitive abstraction
layer over gluoncv to allow even the most novice users to experiment with computer vision.

\sphinxAtStartPar
Comp Viz currently only supports object detection tasks, but in the near future aims to add support for
classification and image segmentation.

\sphinxAtStartPar
Comp Viz is a package currently composed of two subpackages\sphinxhyphen{} object\_detection, which contains the model module,
allowing for object detection related tasks, and the utils sub package, which hosts a variety of helper
functions to better interact with, but not limited to, other comp viz subpackages.


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\sphinxthistablewithborderlessstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxtableatstartofbodyhook
\noindent\sphinxincludegraphics{{4}.jpg}
&
\noindent\sphinxincludegraphics{{223}.jpg}
&
\noindent\sphinxincludegraphics{{0}.jpg}
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxstepscope


\chapter{Comp Viz}
\label{\detokenize{modules:comp-viz}}\label{\detokenize{modules::doc}}
\sphinxstepscope


\section{comp\_viz package}
\label{\detokenize{comp_viz:comp-viz-package}}\label{\detokenize{comp_viz::doc}}

\subsection{Subpackages}
\label{\detokenize{comp_viz:subpackages}}
\sphinxstepscope


\subsubsection{Object Detection package}
\label{\detokenize{comp_viz.object_detection:object-detection-package}}\label{\detokenize{comp_viz.object_detection::doc}}

\paragraph{object\_detection.model module}
\label{\detokenize{comp_viz.object_detection:module-comp_viz.object_detection.model}}\label{\detokenize{comp_viz.object_detection:object-detection-model-module}}\index{module@\spxentry{module}!comp\_viz.object\_detection.model@\spxentry{comp\_viz.object\_detection.model}}\index{comp\_viz.object\_detection.model@\spxentry{comp\_viz.object\_detection.model}!module@\spxentry{module}}\index{Model (class in comp\_viz.object\_detection.model)@\spxentry{Model}\spxextra{class in comp\_viz.object\_detection.model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.object\_detection.model.}}\sphinxbfcode{\sphinxupquote{Model}}}{\emph{\DUrole{n}{network\_name}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
Computer vision object detection model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{network\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} A string representing the computer vision network that will be used
for detection.

\sphinxlineitem{Variables}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{net\_name}} \textendash{} Holds the string literal for the chosen computer vision network.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{net}} \textendash{} Holds the crucial mxnet\sphinxhyphen{}gluoncv instantiated computer vision model for which
our package aims to provides a layer of abstraction over.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inference\_resolution}} \textendash{} Stores the resolution of images we are to perform inference on.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{default\_object\_classes}} \textendash{} Stores the default object classes that come with chosen network:

\end{itemize}

\end{description}\end{quote}
\index{get\_classes() (comp\_viz.object\_detection.model.Model method)@\spxentry{get\_classes()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.get_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_classes}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Get list of the object classes that the computer vision model is detecting for in images.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
List

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_image\_prediction() (comp\_viz.object\_detection.model.Model method)@\spxentry{get\_image\_prediction()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.get_image_prediction}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_image\_prediction}}}{\emph{\DUrole{n}{fname}}, \emph{\DUrole{n}{nms}\DUrole{o}{=}\DUrole{default_value}{0.0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get image with the bounding box detections and the prediction made by the computer vision model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to an image file.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nms}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Stands for non\sphinxhyphen{}maximal suppresion. If computer vision model detects and an 
object in the image with a confidence value less than the nms value, it 
will not include it in the returned results.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A pair of values, an image in the form of a numpy array, and the prediction dict.

\sphinxlineitem{Return type}
\sphinxAtStartPar
(numpy.array, dict)

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_prediction() (comp\_viz.object\_detection.model.Model method)@\spxentry{get\_prediction()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.get_prediction}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_prediction}}}{\emph{\DUrole{n}{fname}}, \emph{\DUrole{n}{nms}\DUrole{o}{=}\DUrole{default_value}{0.0}}}{{ $\rightarrow$ dict}}
\pysigstopsignatures
\sphinxAtStartPar
Get prediction made for an image by computer vision model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to an image file.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nms}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Stands for non\sphinxhyphen{}maximal suppresion. If computer vision model detects and an 
object in the image with a confidence value less than the nms value, it 
will not include it in the returned results.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{list\_classes() (comp\_viz.object\_detection.model.Model method)@\spxentry{list\_classes()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.list_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{list\_classes}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Print the object classes that the computer vision model is detecting for in images.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{reset\_classes() (comp\_viz.object\_detection.model.Model method)@\spxentry{reset\_classes()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.reset_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{reset\_classes}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Change the object classes that the computer vision model is detecting for in images back to defaults.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_classes() (comp\_viz.object\_detection.model.Model method)@\spxentry{set\_classes()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.set_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_classes}}}{\emph{\DUrole{n}{object\_classes}\DUrole{p}{:}\DUrole{w}{  }\DUrole{n}{list}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Change the object classes that the computer vision model is detecting for in images. Ensures validity by referencing the original list of available object classes when model was first instantiatied.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{object\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} List of new object classes to detect for. Ex. “person”, “bicycle”, “banana”.

\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{show\_image\_prediction() (comp\_viz.object\_detection.model.Model method)@\spxentry{show\_image\_prediction()}\spxextra{comp\_viz.object\_detection.model.Model method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.object_detection:comp_viz.object_detection.model.Model.show_image_prediction}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{show\_image\_prediction}}}{\emph{\DUrole{n}{fname}}, \emph{\DUrole{n}{nms}\DUrole{o}{=}\DUrole{default_value}{0.0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Print image with the bounding box detections and the prediction made by the computer vision model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to an image file.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nms}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Stands for non\sphinxhyphen{}maximal suppresion. If computer vision model detects and an 
object in the image with a confidence value less than the nms value, it 
will not include it in the returned results.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\paragraph{Module contents}
\label{\detokenize{comp_viz.object_detection:module-comp_viz.object_detection}}\label{\detokenize{comp_viz.object_detection:module-contents}}\index{module@\spxentry{module}!comp\_viz.object\_detection@\spxentry{comp\_viz.object\_detection}}\index{comp\_viz.object\_detection@\spxentry{comp\_viz.object\_detection}!module@\spxentry{module}}

\paragraph{model.py}
\label{\detokenize{comp_viz.object_detection:model-py}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Author(s): Lucas Hirt}
\PYG{c+c1}{\PYGZsh{} Date Modified: 11/27/2022}

\PYG{k+kn}{import} \PYG{n+nn}{mxnet}
\PYG{k+kn}{import} \PYG{n+nn}{gluoncv}
\PYG{k+kn}{import} \PYG{n+nn}{numpy}
\PYG{k+kn}{import} \PYG{n+nn}{time}

\PYG{k+kn}{from} \PYG{n+nn}{.}\PYG{n+nn}{.} \PYG{k+kn}{import} \PYG{n}{utils}

\PYG{k}{class} \PYG{n+nc}{Model}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Computer vision object detection model.}

\PYG{l+s+sd}{  :param network\PYGZus{}name: A string representing the computer vision network that will be used}
\PYG{l+s+sd}{                       for detection.}
\PYG{l+s+sd}{  :type network\PYGZus{}name: string}
\PYG{l+s+sd}{  :ivar net\PYGZus{}name: Holds the string literal for the chosen computer vision network.}
\PYG{l+s+sd}{  :ivar net: Holds the crucial mxnet\PYGZhy{}gluoncv instantiated computer vision model for which}
\PYG{l+s+sd}{             our package aims to provides a layer of abstraction over.}
\PYG{l+s+sd}{  :ivar inference\PYGZus{}resolution: Stores the resolution of images we are to perform inference on.}
\PYG{l+s+sd}{  :ivar default\PYGZus{}object\PYGZus{}classes: Stores the default object classes that come with chosen network:}
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}

  \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{network\PYGZus{}name}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Constructor method}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}name} \PYG{o}{=} \PYG{n}{network\PYGZus{}name}
    \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net} \PYG{o}{=} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{model\PYGZus{}zoo}\PYG{o}{.}\PYG{n}{get\PYGZus{}model}\PYG{p}{(}\PYG{n}{network\PYGZus{}name}\PYG{p}{,} \PYG{n}{pretrained}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
    \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{inference\PYGZus{}resolution} \PYG{o}{=} \PYG{n}{utils}\PYG{o}{.}\PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{get\PYGZus{}network\PYGZus{}resolution}\PYG{p}{(}\PYG{n}{network\PYGZus{}name}\PYG{p}{)}
    \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{default\PYGZus{}object\PYGZus{}classes} \PYG{o}{=} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{model\PYGZus{}zoo}\PYG{o}{.}\PYG{n}{get\PYGZus{}model}\PYG{p}{(}\PYG{n}{network\PYGZus{}name}\PYG{p}{,} \PYG{n}{pretrained}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{classes}

  \PYG{k}{def} \PYG{n+nf}{list\PYGZus{}classes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Print the object classes that the computer vision model is detecting for in images.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}classes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}classes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Get list of the object classes that the computer vision model is detecting for in images.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :rtype: List}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{return} \PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}classes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}prediction}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{fname}\PYG{p}{,}\PYG{n}{nms}\PYG{o}{=}\PYG{l+m+mf}{0.}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n+nb}{dict}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Get prediction made for an image by computer vision model.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :param fname: Path to an image file.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :param nms: Stands for non\PYGZhy{}maximal suppresion. If computer vision model detects and an }
\PYG{l+s+sd}{                object in the image with a confidence value less than the nms value, it }
\PYG{l+s+sd}{                will not include it in the returned results. }
\PYG{l+s+sd}{    :type nms: float}
\PYG{l+s+sd}{    :rtype: dict            }
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{utils}\PYG{o}{.}\PYG{n}{Tools}\PYG{o}{.}\PYG{n}{verify\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{n}{start} \PYG{o}{=} \PYG{n}{time}\PYG{o}{.}\PYG{n}{time}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{cids}\PYG{p}{,} \PYG{n}{scores}\PYG{p}{,} \PYG{n}{bboxes} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}predict}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{,}\PYG{n}{nms}\PYG{p}{)}
    \PYG{n}{end} \PYG{o}{=} \PYG{n}{time}\PYG{o}{.}\PYG{n}{time}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{prediction} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{image}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{class\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{cids}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{confidence\PYGZus{}scores}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{scores}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bounding\PYGZus{}boxes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bboxes}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{nms\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{nms}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{class\PYGZus{}map}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{n}{cid}\PYG{p}{:} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{get\PYGZus{}classes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{[}\PYG{n}{cid}\PYG{p}{]} \PYG{k}{for} \PYG{n}{cid} \PYG{o+ow}{in} \PYG{n+nb}{set}\PYG{p}{(}\PYG{n}{cids}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{time}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n+nb}{round}\PYG{p}{(}\PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{end} \PYG{o}{\PYGZhy{}} \PYG{n}{start}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{network}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}name}
    \PYG{n}{prediction}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{resolution}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{inference\PYGZus{}resolution}
    \PYG{k}{return} \PYG{n}{prediction}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}image\PYGZus{}prediction}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{fname}\PYG{p}{,}\PYG{n}{nms}\PYG{o}{=}\PYG{l+m+mf}{0.}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Get image with the bounding box detections and the prediction made by the computer vision model.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :param fname: Path to an image file.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :param nms: Stands for non\PYGZhy{}maximal suppresion. If computer vision model detects and an }
\PYG{l+s+sd}{                object in the image with a confidence value less than the nms value, it }
\PYG{l+s+sd}{                will not include it in the returned results.}
\PYG{l+s+sd}{    :type nms: float}
\PYG{l+s+sd}{    :return: A pair of values, an image in the form of a numpy array, and the prediction dict.}
\PYG{l+s+sd}{    :rtype: (numpy.array, dict)}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{pred} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{get\PYGZus{}prediction}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{,}\PYG{n}{nms}\PYG{p}{)}
    \PYG{n}{pred\PYGZus{}img} \PYG{o}{=} \PYG{n}{utils}\PYG{o}{.}\PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{get\PYGZus{}pred\PYGZus{}bboxes\PYGZus{}image}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{,}
                                                           \PYG{n}{pred}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bounding\PYGZus{}boxes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                                                           \PYG{n}{pred}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{class\PYGZus{}ids}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                                                           \PYG{p}{[}\PYG{n}{val} \PYG{k}{for} \PYG{n}{val} \PYG{o+ow}{in} \PYG{n}{pred}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{class\PYGZus{}map}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
                                                           \PYG{n}{pred}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{confidence\PYGZus{}scores}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{pred\PYGZus{}img}\PYG{p}{,} \PYG{n}{pred}

  \PYG{k}{def} \PYG{n+nf}{show\PYGZus{}image\PYGZus{}prediction}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{fname}\PYG{p}{,}\PYG{n}{nms}\PYG{o}{=}\PYG{l+m+mf}{0.}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Print image with the bounding box detections and the prediction made by the computer vision model.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :param fname: Path to an image file.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :param nms: Stands for non\PYGZhy{}maximal suppresion. If computer vision model detects and an }
\PYG{l+s+sd}{                object in the image with a confidence value less than the nms value, it }
\PYG{l+s+sd}{                will not include it in the returned results.}
\PYG{l+s+sd}{    :type nms: float}
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{image}\PYG{p}{,} \PYG{n}{prediction} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{get\PYGZus{}image\PYGZus{}prediction}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{n}{utils}\PYG{o}{.}\PYG{n}{Tools}\PYG{o}{.}\PYG{n}{show\PYGZus{}image}\PYG{p}{(}\PYG{n}{image}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{prediction}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{set\PYGZus{}classes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{object\PYGZus{}classes}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Change the object classes that the computer vision model is detecting for in images. Ensures validity by referencing the original list of available object classes when model was first instantiatied.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :param object\PYGZus{}classes: List of new object classes to detect for. Ex. \PYGZdq{}person\PYGZdq{}, \PYGZdq{}bicycle\PYGZdq{}, \PYGZdq{}banana\PYGZdq{}.}
\PYG{l+s+sd}{    :type object\PYGZus{}classes: List}
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{unsupported} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{obj\PYGZus{}class} \PYG{o+ow}{in} \PYG{n}{object\PYGZus{}classes}\PYG{p}{:}
      \PYG{k}{if} \PYG{n}{obj\PYGZus{}class} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{default\PYGZus{}object\PYGZus{}classes}\PYG{p}{:}
        \PYG{n}{unsupported}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{obj\PYGZus{}class}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{unsupported}\PYG{p}{:}    
      \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{WARNING: object classes }\PYG{l+s+se}{\PYGZbs{}\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{unsupported}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}\PYGZdq{}}\PYG{l+s+s2}{ are not supported by default for object detection. Expect no capability for detection.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net}\PYG{o}{.}\PYG{n}{reset\PYGZus{}class}\PYG{p}{(}\PYG{n}{object\PYGZus{}classes}\PYG{p}{,} \PYG{n}{reuse\PYGZus{}weights}\PYG{o}{=}\PYG{n}{object\PYGZus{}classes}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Complete. Model set to detect for object classes: }\PYG{l+s+si}{\PYGZob{}}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{get\PYGZus{}classes}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{reset\PYGZus{}classes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Change the object classes that the computer vision model is detecting for in images back to defaults.}

\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net}\PYG{o}{.}\PYG{n}{reset\PYGZus{}class}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{default\PYGZus{}object\PYGZus{}classes}\PYG{p}{,}\PYG{n}{reuse\PYGZus{}weights}\PYG{o}{=}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{default\PYGZus{}object\PYGZus{}classes}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Object classes for detection restored to defaults.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

  \PYG{c+c1}{\PYGZsh{} Get tuple containing class ids, confidence scores and bounding boxes for an image prediction,}
  \PYG{c+c1}{\PYGZsh{} apply NMS if specified and return the tuple.}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}predict}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{fname}\PYG{p}{,}\PYG{n}{nms}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n+nb}{tuple}\PYG{p}{:}
    \PYG{n}{base\PYGZus{}img} \PYG{o}{=} \PYG{n}{mxnet}\PYG{o}{.}\PYG{n}{image}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{n}{x}\PYG{p}{,} \PYG{n}{img} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}\PYGZus{}prepare\PYGZus{}image}\PYG{p}{(}\PYG{n}{base\PYGZus{}img}\PYG{p}{)}
    \PYG{n}{pred} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
    \PYG{n}{cids}\PYG{p}{,} \PYG{n}{scores}\PYG{p}{,} \PYG{n}{bboxes} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}extract\PYGZus{}cids\PYGZus{}scores\PYGZus{}bboxes}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{)}
    \PYG{c+c1}{\PYGZsh{} resize bounding box from network inference resolution to original image resolution}
    \PYG{n}{bboxes} \PYG{o}{=} \PYG{p}{[}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{resize\PYGZus{}bbox}\PYG{p}{(}\PYG{n}{bbox}\PYG{p}{,}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{,}\PYG{n}{base\PYGZus{}img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)} \PYG{k}{for} \PYG{n}{bbox} \PYG{o+ow}{in} \PYG{n}{bboxes}\PYG{p}{]}
    \PYG{k}{if} \PYG{n}{nms} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{:}
      \PYG{k}{return} \PYG{p}{(}\PYG{n}{cids}\PYG{p}{,}\PYG{n}{scores}\PYG{p}{,}\PYG{n}{bboxes}\PYG{p}{)}
    \PYG{n}{nms\PYGZus{}cids}\PYG{p}{,} \PYG{n}{nms\PYGZus{}scores}\PYG{p}{,} \PYG{n}{nms\PYGZus{}bboxes} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}apply\PYGZus{}nms}\PYG{p}{(}\PYG{n}{cids}\PYG{p}{,} \PYG{n}{scores}\PYG{p}{,} \PYG{n}{bboxes}\PYG{p}{,} \PYG{n}{nms}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{nms\PYGZus{}cids}\PYG{p}{,}\PYG{n}{nms\PYGZus{}scores}\PYG{p}{,}\PYG{n}{nms\PYGZus{}bboxes}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}classes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net}\PYG{o}{.}\PYG{n}{classes}
    
  \PYG{c+c1}{\PYGZsh{} Return tuple containing only the class ids, confidence scores, and bounding boxes of an MXNet}
  \PYG{c+c1}{\PYGZsh{} inference result.}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}extract\PYGZus{}cids\PYGZus{}scores\PYGZus{}bboxes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{pred}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{cids} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}class\PYGZus{}ids}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{scores} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}scores}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{bboxes} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}bboxes}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{cids}\PYG{p}{,} \PYG{n}{scores}\PYG{p}{,} \PYG{n}{bboxes}\PYG{p}{)}

  \PYG{c+c1}{\PYGZsh{} Given an tuple containing class ids, confidence scoers and bounding boxes for an MXNet prediction}
  \PYG{c+c1}{\PYGZsh{} filter the results and return them based off the confidence scores of the predictions and the}
  \PYG{c+c1}{\PYGZsh{} specified nms value. (If confidence score \PYGZlt{} NMS, prune that prediction from results to be returned.)}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}apply\PYGZus{}nms}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{cids}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{scores}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{bboxes}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{nms}\PYG{p}{:} \PYG{n+nb}{float}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{prune\PYGZus{}indexes} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{score} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{scores}\PYG{p}{)}\PYG{p}{:}
      \PYG{k}{if} \PYG{n}{score} \PYG{o}{\PYGZlt{}} \PYG{n}{nms}\PYG{p}{:}
        \PYG{n}{prune\PYGZus{}indexes}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}
    \PYG{k}{for} \PYG{n}{index} \PYG{o+ow}{in} \PYG{n}{prune\PYGZus{}indexes}\PYG{p}{[}\PYG{p}{:}\PYG{p}{:}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{:}
      \PYG{n}{cids}\PYG{o}{.}\PYG{n}{pop}\PYG{p}{(}\PYG{n}{index}\PYG{p}{)}
      \PYG{n}{scores}\PYG{o}{.}\PYG{n}{pop}\PYG{p}{(}\PYG{n}{index}\PYG{p}{)}
      \PYG{n}{bboxes}\PYG{o}{.}\PYG{n}{pop}\PYG{p}{(}\PYG{n}{index}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{(}\PYG{n}{cids}\PYG{p}{,} \PYG{n}{scores}\PYG{p}{,} \PYG{n}{bboxes}\PYG{p}{)}

  \PYG{c+c1}{\PYGZsh{} Extract the class ids from an MXNet prediction ndarray to a list.}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}class\PYGZus{}ids}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{cids}\PYG{p}{:} \PYG{n}{numpy}\PYG{o}{.}\PYG{n}{ndarray}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n+nb}{list}\PYG{p}{:}
    \PYG{n}{class\PYGZus{}ids} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{ndarray} \PYG{o+ow}{in} \PYG{n}{cids}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{:}
      \PYG{n}{nparray} \PYG{o}{=} \PYG{n}{ndarray}\PYG{o}{.}\PYG{n}{asnumpy}\PYG{p}{(}\PYG{p}{)}
      \PYG{k}{if} \PYG{n}{nparray}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{!=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{:}
        \PYG{n}{class\PYGZus{}ids}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n+nb}{int}\PYG{p}{(}\PYG{n}{nparray}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{class\PYGZus{}ids}

  \PYG{c+c1}{\PYGZsh{} Extract the confidence score float values from an MXNet prediction ndarray to a list}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}scores}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{scores}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{confidence\PYGZus{}scores} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{ndarray} \PYG{o+ow}{in} \PYG{n}{scores}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{:}
      \PYG{n}{nparray} \PYG{o}{=} \PYG{n}{ndarray}\PYG{o}{.}\PYG{n}{asnumpy}\PYG{p}{(}\PYG{p}{)}
      \PYG{k}{if} \PYG{n}{nparray}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{!=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{:}
        \PYG{n}{confidence\PYGZus{}scores}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n+nb}{round}\PYG{p}{(}\PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{nparray}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{confidence\PYGZus{}scores}

  \PYG{c+c1}{\PYGZsh{} Extract the bounding boxes from an MXNet prediction ndarray to a nested list }
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}bboxes}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{bboxes}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{bounding\PYGZus{}boxes} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{ndarray} \PYG{o+ow}{in} \PYG{n}{bboxes}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{:}
      \PYG{n}{nparray} \PYG{o}{=} \PYG{n}{ndarray}\PYG{o}{.}\PYG{n}{asnumpy}\PYG{p}{(}\PYG{p}{)}
      \PYG{k}{if} \PYG{n}{nparray}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{!=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{:}
        \PYG{n}{bb} \PYG{o}{=} \PYG{p}{[}\PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{corner}\PYG{p}{)} \PYG{k}{for} \PYG{n}{corner} \PYG{o+ow}{in} \PYG{n}{nparray}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}
        \PYG{n}{bounding\PYGZus{}boxes}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{bb}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{bounding\PYGZus{}boxes}

  \PYG{c+c1}{\PYGZsh{} Process image such that inference can be performed by the mxnet network.}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}\PYGZus{}prepare\PYGZus{}image}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,}\PYG{n}{image}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yolo}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{in} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}name}\PYG{p}{:}
      \PYG{k}{return} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{transforms}\PYG{o}{.}\PYG{n}{presets}\PYG{o}{.}\PYG{n}{yolo}\PYG{o}{.}\PYG{n}{transform\PYGZus{}test}\PYG{p}{(}\PYG{n}{image}\PYG{p}{,}\PYG{n}{short}\PYG{o}{=}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{inference\PYGZus{}resolution}\PYG{p}{)}
    \PYG{k}{elif} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rcnn}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{in} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}name}\PYG{p}{:}
      \PYG{k}{return} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{transforms}\PYG{o}{.}\PYG{n}{presets}\PYG{o}{.}\PYG{n}{rcnn}\PYG{o}{.}\PYG{n}{transform\PYGZus{}test}\PYG{p}{(}\PYG{n}{image}\PYG{p}{,}\PYG{n}{short}\PYG{o}{=}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{inference\PYGZus{}resolution}\PYG{p}{)}
    \PYG{k}{elif} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ssd}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{in} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}name}\PYG{p}{:}
      \PYG{k}{return} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{transforms}\PYG{o}{.}\PYG{n}{presets}\PYG{o}{.}\PYG{n}{ssd}\PYG{o}{.}\PYG{n}{transform\PYGZus{}test}\PYG{p}{(}\PYG{n}{image}\PYG{p}{,}\PYG{n}{short}\PYG{o}{=}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{inference\PYGZus{}resolution}\PYG{p}{)}
    \PYG{k}{elif} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{center\PYGZus{}net}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{in} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}name}\PYG{p}{:}
      \PYG{k}{return} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{transforms}\PYG{o}{.}\PYG{n}{presets}\PYG{o}{.}\PYG{n}{center\PYGZus{}net}\PYG{o}{.}\PYG{n}{transform\PYGZus{}test}\PYG{p}{(}\PYG{n}{image}\PYG{p}{,}\PYG{n}{short}\PYG{o}{=}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{inference\PYGZus{}resolution}\PYG{p}{)}
\end{sphinxVerbatim}


\paragraph{\_\_init\_\_.py}
\label{\detokenize{comp_viz.object_detection:init-py}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{.}\PYG{n+nn}{model} \PYG{k+kn}{import} \PYG{o}{*}
\end{sphinxVerbatim}

\sphinxstepscope


\subsubsection{Utils package}
\label{\detokenize{comp_viz.utils:utils-package}}\label{\detokenize{comp_viz.utils::doc}}

\paragraph{utils.toolbox module}
\label{\detokenize{comp_viz.utils:module-comp_viz.utils.toolbox}}\label{\detokenize{comp_viz.utils:utils-toolbox-module}}\index{module@\spxentry{module}!comp\_viz.utils.toolbox@\spxentry{comp\_viz.utils.toolbox}}\index{comp\_viz.utils.toolbox@\spxentry{comp\_viz.utils.toolbox}!module@\spxentry{module}}\index{Models (class in comp\_viz.utils.toolbox)@\spxentry{Models}\spxextra{class in comp\_viz.utils.toolbox}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Models}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.utils.toolbox.}}\sphinxbfcode{\sphinxupquote{Models}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
Utility class centered around conveying available functionality for the comp\_viz package.
\index{get\_tasks() (comp\_viz.utils.toolbox.Models method)@\spxentry{get\_tasks()}\spxextra{comp\_viz.utils.toolbox.Models method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Models.get_tasks}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_tasks}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Get available tasks for the comp\_viz package.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{list\_tasks() (comp\_viz.utils.toolbox.Models method)@\spxentry{list\_tasks()}\spxextra{comp\_viz.utils.toolbox.Models method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Models.list_tasks}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{list\_tasks}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Show available tasks for the comp\_viz package.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{ObjectDetection (class in comp\_viz.utils.toolbox)@\spxentry{ObjectDetection}\spxextra{class in comp\_viz.utils.toolbox}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.utils.toolbox.}}\sphinxbfcode{\sphinxupquote{ObjectDetection}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
Utility class centered around object detection tasks relevant but not limited to the comp\_viz object detection package.
\index{format\_object\_classes() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{format\_object\_classes()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.format_object_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{format\_object\_classes}}}{}{{ $\rightarrow$ list}}
\pysigstopsignatures
\sphinxAtStartPar
Given a list of object classes, format all the elements such that they are readable by the network.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{object\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) \textendash{} List of object classes.

\sphinxlineitem{Return type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_network\_resolution() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{get\_network\_resolution()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.get_network_resolution}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_network\_resolution}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Get image inference resolution of the specified network.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{net\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} A valid network name among the results in get\_networks() or list\_networks() method.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_networks() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{get\_networks()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.get_networks}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_networks}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Get list of the available networks that can be used with the comp\_viz object\_detection sub\sphinxhyphen{}package.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
List

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pred\_bboxes\_image() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{get\_pred\_bboxes\_image()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.get_pred_bboxes_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_pred\_bboxes\_image}}}{\emph{\DUrole{n}{bboxes}\DUrole{p}{:}\DUrole{w}{  }\DUrole{n}{list}}, \emph{\DUrole{n}{labels}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{class\_names}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{scores}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Given an image and detection bounding box features, plot the bounding box to the image and return it.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{img\_fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to image to plot bounding box to.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bboxes}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Bounding boxes of form {[}{[}x\_min,y\_min,x\_max,y\_max{]},…{]} to plot to the image/

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{labels}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Class id values to mape to each bounding box and class name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_names}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of object classes:

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{scores}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of confidence values for the bounding boxes.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{list\_networks() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{list\_networks()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.list_networks}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{list\_networks}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Show list of the available networks that can be used with the comp\_viz object\_detection sub\sphinxhyphen{}package.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{resize\_bbox() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{resize\_bbox()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.resize_bbox}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{resize\_bbox}}}{\emph{\DUrole{n}{orig}\DUrole{p}{:}\DUrole{w}{  }\DUrole{n}{tuple}}, \emph{\DUrole{n}{dest}\DUrole{p}{:}\DUrole{w}{  }\DUrole{n}{tuple}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Given a bounding box of the format {[}x,min, y\_min, x\_max, y\_max{]} and the original image resolution, return a new bounding box resized to the desired image size.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bbox}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) \textendash{} Bounding box of the form {[}x\_min, y\_min, x\_max, y\_max{]}.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{orig}} (\sphinxstyleliteralemphasis{\sphinxupquote{Tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{ndarray.shape}}) \textendash{} Original image resolution of form (height, width, shape). Ex. (500,800,3)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dest}} (\sphinxstyleliteralemphasis{\sphinxupquote{Tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{ndarray.shape}}) \textendash{} Image to resize resolution of form (height, width, shape). Ex. (600,900,3)

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{show\_pred\_bboxes\_image() (comp\_viz.utils.toolbox.ObjectDetection method)@\spxentry{show\_pred\_bboxes\_image()}\spxextra{comp\_viz.utils.toolbox.ObjectDetection method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.ObjectDetection.show_pred_bboxes_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{show\_pred\_bboxes\_image}}}{\emph{\DUrole{n}{bboxes}\DUrole{p}{:}\DUrole{w}{  }\DUrole{n}{list}}, \emph{\DUrole{n}{labels}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{class\_names}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}, \emph{\DUrole{n}{scores}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Given an image and detection bounding box features, plot the bounding box to the image and show it.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{img\_fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to image to plot bounding box to.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bboxes}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Bounding boxes of form {[}{[}x\_min,y\_min,x\_max,y\_max{]},…{]} to plot to the image/

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{labels}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Class id values to mape to each bounding box and class name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_names}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of object classes:

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{scores}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of confidence values for the bounding boxes.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{Tools (class in comp\_viz.utils.toolbox)@\spxentry{Tools}\spxextra{class in comp\_viz.utils.toolbox}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.utils.toolbox.}}\sphinxbfcode{\sphinxupquote{Tools}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
Utility class centered around images and filesnames.
\index{exists() (comp\_viz.utils.toolbox.Tools method)@\spxentry{exists()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.exists}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{exists}}}{}{{ $\rightarrow$ bool}}
\pysigstopsignatures
\sphinxAtStartPar
Boolean function to determine if path to filename exists.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to file.

\sphinxlineitem{Return type}
\sphinxAtStartPar
boolean

\end{description}\end{quote}

\end{fulllineitems}

\index{filename\_show\_image() (comp\_viz.utils.toolbox.Tools method)@\spxentry{filename\_show\_image()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.filename_show_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{filename\_show\_image}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Given path to an image file, show the said image file to the screen.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to image.

\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_cv2\_image() (comp\_viz.utils.toolbox.Tools method)@\spxentry{get\_cv2\_image()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.get_cv2_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_cv2\_image}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Given path to an image file, return the said image in the form of an numpy ndarray using openCV.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to file.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_mxnet\_image() (comp\_viz.utils.toolbox.Tools method)@\spxentry{get\_mxnet\_image()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.get_mxnet_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_mxnet\_image}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Given path to an image file, return the said image in the form of an mxnet ndarray.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fname}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to file.

\sphinxlineitem{Return type}
\sphinxAtStartPar
mxnet.ndarray.ndarray.NDArray

\end{description}\end{quote}

\end{fulllineitems}

\index{save\_image() (comp\_viz.utils.toolbox.Tools method)@\spxentry{save\_image()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.save_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{save\_image}}}{\emph{\DUrole{n}{path}\DUrole{p}{:}\DUrole{w}{  }\DUrole{n}{str}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Given an image in the form of an ndarray, save it to the path specified.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{img}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{mxnet.ndarray.ndarray.NDArray}}) \textendash{} Image in the form of an ndarray.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} Path to save image to.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{show\_image() (comp\_viz.utils.toolbox.Tools method)@\spxentry{show\_image()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.show_image}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{show\_image}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Given an image in the form of an numpy ndarray, show the image to the screen.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{img}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{mxnet.ndarray.ndarray.NDArray}}) \textendash{} Image in the form of an ndarray.

\sphinxlineitem{Return type}
\sphinxAtStartPar
void

\end{description}\end{quote}

\end{fulllineitems}

\index{verify\_exists() (comp\_viz.utils.toolbox.Tools method)@\spxentry{verify\_exists()}\spxextra{comp\_viz.utils.toolbox.Tools method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz.utils:comp_viz.utils.toolbox.Tools.verify_exists}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{verify\_exists}}}{}{}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}



\paragraph{Module contents}
\label{\detokenize{comp_viz.utils:module-comp_viz.utils}}\label{\detokenize{comp_viz.utils:module-contents}}\index{module@\spxentry{module}!comp\_viz.utils@\spxentry{comp\_viz.utils}}\index{comp\_viz.utils@\spxentry{comp\_viz.utils}!module@\spxentry{module}}

\paragraph{toolbox.py}
\label{\detokenize{comp_viz.utils:toolbox-py}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Author(s): Lucas Hirt}
\PYG{c+c1}{\PYGZsh{} Date Modified: 11/27/2022}

\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{import} \PYG{n+nn}{mxnet}
\PYG{k+kn}{import} \PYG{n+nn}{gluoncv}
\PYG{k+kn}{import} \PYG{n+nn}{numpy}
\PYG{k+kn}{import} \PYG{n+nn}{cv2}

\PYG{k+kn}{from} \PYG{n+nn}{.}\PYG{n+nn}{.}\PYG{n+nn}{config} \PYG{k+kn}{import} \PYG{n}{Models} \PYG{k}{as} \PYG{n}{models\PYGZus{}config}
\PYG{k+kn}{from} \PYG{n+nn}{.}\PYG{n+nn}{.}\PYG{n+nn}{config} \PYG{k+kn}{import} \PYG{n}{ObjectDetection} \PYG{k}{as} \PYG{n}{obj\PYGZus{}det\PYGZus{}config}

\PYG{k}{class} \PYG{n+nc}{Models}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Utility class centered around conveying available functionality for the comp\PYGZus{}viz package. }
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}

  \PYG{k}{def} \PYG{n+nf}{list\PYGZus{}tasks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Show available tasks for the comp\PYGZus{}viz package. }

\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{Models}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}tasks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}tasks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Get available tasks for the comp\PYGZus{}viz package. }
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    :rtype: list}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{return} \PYG{n}{Models}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}tasks}\PYG{p}{(}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}tasks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{models\PYGZus{}config}\PYG{o}{.}\PYG{n}{tasks}


\PYG{k}{class} \PYG{n+nc}{ObjectDetection}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Utility class centered around object detection tasks relevant but not limited to the comp\PYGZus{}viz object detection package.}
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}

  \PYG{k}{def} \PYG{n+nf}{list\PYGZus{}networks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Show list of the available networks that can be used with the comp\PYGZus{}viz object\PYGZus{}detection sub\PYGZhy{}package.}

\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}networks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}networks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Get list of the available networks that can be used with the comp\PYGZus{}viz object\PYGZus{}detection sub\PYGZhy{}package.}

\PYG{l+s+sd}{    :rtype: List}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{return} \PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}networks}\PYG{p}{(}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}network\PYGZus{}resolution}\PYG{p}{(}\PYG{n}{net\PYGZus{}name}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Get image inference resolution of the specified network.}

\PYG{l+s+sd}{    :param net\PYGZus{}name: A valid network name among the results in get\PYGZus{}networks() or list\PYGZus{}networks() method.}
\PYG{l+s+sd}{    :type net\PYGZus{}name: string}
\PYG{l+s+sd}{    :rtype: int}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{return} \PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{\PYGZus{}get\PYGZus{}resolution}\PYG{p}{(}\PYG{n}{net\PYGZus{}name}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{format\PYGZus{}object\PYGZus{}classes}\PYG{p}{(}\PYG{n}{object\PYGZus{}classes}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n+nb}{list}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given a list of object classes, format all the elements such that they are readable by the network.}

\PYG{l+s+sd}{    :param object\PYGZus{}classes: List of object classes.}
\PYG{l+s+sd}{    :type object\PYGZus{}classes: list}
\PYG{l+s+sd}{    :rtype: list}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{i} \PYG{o}{=} \PYG{l+m+mi}{0}
    \PYG{k}{while} \PYG{n}{i} \PYG{o}{\PYGZlt{}} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{object\PYGZus{}classes}\PYG{p}{)}\PYG{p}{:}
      \PYG{k}{if} \PYG{n}{object\PYGZus{}classes}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{n}{object\PYGZus{}classes}\PYG{o}{.}\PYG{n}{pop}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}
        \PYG{k}{continue}
      \PYG{n}{object\PYGZus{}classes}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{n}{object\PYGZus{}classes}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{lower}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strip}\PYG{p}{(}\PYG{p}{)}
      \PYG{n}{i} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1}
    \PYG{k}{return} \PYG{n}{object\PYGZus{}classes}

  \PYG{k}{def} \PYG{n+nf}{resize\PYGZus{}bbox}\PYG{p}{(}\PYG{n}{bbox}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{orig}\PYG{p}{:} \PYG{n+nb}{tuple}\PYG{p}{,} \PYG{n}{dest}\PYG{p}{:} \PYG{n+nb}{tuple}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given a bounding box of the format [x,min, y\PYGZus{}min, x\PYGZus{}max, y\PYGZus{}max] and the original image resolution, return a new bounding box resized to the desired image size.}

\PYG{l+s+sd}{    :param bbox: Bounding box of the form [x\PYGZus{}min, y\PYGZus{}min, x\PYGZus{}max, y\PYGZus{}max].}
\PYG{l+s+sd}{    :type bbox: list}
\PYG{l+s+sd}{    :param orig: Original image resolution of form (height, width, shape). Ex. (500,800,3)}
\PYG{l+s+sd}{    :type orig: Tuple or ndarray.shape}
\PYG{l+s+sd}{    :param dest: Image to resize resolution of form (height, width, shape). Ex. (600,900,3)}
\PYG{l+s+sd}{    :type dest: Tuple or ndarray.shape}
\PYG{l+s+sd}{    :rtype: list}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{x\PYGZus{}min}\PYG{p}{,} \PYG{n}{y\PYGZus{}min}\PYG{p}{,} \PYG{n}{x\PYGZus{}max}\PYG{p}{,} \PYG{n}{y\PYGZus{}max} \PYG{o}{=} \PYG{n}{bbox}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{bbox}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{bbox}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{bbox}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}
    \PYG{n}{x\PYGZus{}scale} \PYG{o}{=} \PYG{n}{dest}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{/} \PYG{n}{orig}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}
    \PYG{n}{y\PYGZus{}scale} \PYG{o}{=} \PYG{n}{dest}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{/} \PYG{n}{orig}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{k}{return} \PYG{p}{[}\PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{x\PYGZus{}min}\PYG{o}{*}\PYG{n}{x\PYGZus{}scale}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} 
            \PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{y\PYGZus{}min}\PYG{o}{*}\PYG{n}{y\PYGZus{}scale}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
            \PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{x\PYGZus{}max}\PYG{o}{*}\PYG{n}{x\PYGZus{}scale}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
            \PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{y\PYGZus{}max}\PYG{o}{*}\PYG{n}{y\PYGZus{}scale}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}

  \PYG{k}{def} \PYG{n+nf}{show\PYGZus{}pred\PYGZus{}bboxes\PYGZus{}image}\PYG{p}{(}\PYG{n}{img\PYGZus{}fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{,} \PYG{n}{bboxes}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{labels} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}\PYG{p}{,} \PYG{n}{class\PYGZus{}names} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}\PYG{p}{,} \PYG{n}{scores} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given an image and detection bounding box features, plot the bounding box to the image and show it.}

\PYG{l+s+sd}{    :param img\PYGZus{}fname: Path to image to plot bounding box to.}
\PYG{l+s+sd}{    :type img\PYGZus{}fname: string}
\PYG{l+s+sd}{    :param bboxes: Bounding boxes of form [[x\PYGZus{}min,y\PYGZus{}min,x\PYGZus{}max,y\PYGZus{}max],...] to plot to the image/}
\PYG{l+s+sd}{    :type bboxes: List[List]}
\PYG{l+s+sd}{    :param labels: Class id values to mape to each bounding box and class name.}
\PYG{l+s+sd}{    :type labels: List[int]}
\PYG{l+s+sd}{    :param class\PYGZus{}names: List of object classes:}
\PYG{l+s+sd}{    :type class\PYGZus{}names: List[string]}
\PYG{l+s+sd}{    :param scores: List of confidence values for the bounding boxes.}
\PYG{l+s+sd}{    :type scores: List[float]}
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{img} \PYG{o}{=} \PYG{n}{ObjectDetection}\PYG{o}{.}\PYG{n}{get\PYGZus{}pred\PYGZus{}bboxes\PYGZus{}image}\PYG{p}{(}\PYG{n}{img\PYGZus{}fname}\PYG{p}{,}\PYG{n}{bboxes}\PYG{p}{,}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{class\PYGZus{}names}\PYG{p}{,}\PYG{n}{scores}\PYG{p}{)}
    \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{show\PYGZus{}image}\PYG{p}{(}\PYG{n}{img}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}pred\PYGZus{}bboxes\PYGZus{}image}\PYG{p}{(}\PYG{n}{img\PYGZus{}fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{,} \PYG{n}{bboxes}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{labels} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}\PYG{p}{,} \PYG{n}{class\PYGZus{}names} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}\PYG{p}{,} \PYG{n}{scores} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given an image and detection bounding box features, plot the bounding box to the image and return it.}

\PYG{l+s+sd}{    :param img\PYGZus{}fname: Path to image to plot bounding box to.}
\PYG{l+s+sd}{    :type img\PYGZus{}fname: string}
\PYG{l+s+sd}{    :param bboxes: Bounding boxes of form [[x\PYGZus{}min,y\PYGZus{}min,x\PYGZus{}max,y\PYGZus{}max],...] to plot to the image/}
\PYG{l+s+sd}{    :type bboxes: List[List]}
\PYG{l+s+sd}{    :param labels: Class id values to mape to each bounding box and class name.}
\PYG{l+s+sd}{    :type labels: List[int]}
\PYG{l+s+sd}{    :param class\PYGZus{}names: List of object classes:}
\PYG{l+s+sd}{    :type class\PYGZus{}names: List[string]}
\PYG{l+s+sd}{    :param scores: List of confidence values for the bounding boxes.}
\PYG{l+s+sd}{    :type scores: List[float]}
\PYG{l+s+sd}{    :rtype: numpy.ndarray}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{img} \PYG{o}{=} \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{get\PYGZus{}mxnet\PYGZus{}image}\PYG{p}{(}\PYG{n}{img\PYGZus{}fname}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{viz}\PYG{o}{.}\PYG{n}{cv\PYGZus{}plot\PYGZus{}bbox}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{bboxes}\PYG{p}{)}\PYG{p}{,}\PYG{n}{labels}\PYG{o}{=}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{labels}\PYG{p}{)}\PYG{p}{,}\PYG{n}{scores}\PYG{o}{=}\PYG{n}{numpy}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{scores}\PYG{p}{)}\PYG{p}{,}\PYG{n}{class\PYGZus{}names}\PYG{o}{=}\PYG{n}{class\PYGZus{}names}\PYG{p}{,}\PYG{n}{thresh}\PYG{o}{=}\PYG{l+m+mf}{0.}\PYG{p}{)}

  \PYG{c+c1}{\PYGZsh{} Get list of networks available for object detection from config.py}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}networks}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{p}{[}\PYG{n}{network} \PYG{k}{for} \PYG{n}{network} \PYG{o+ow}{in} \PYG{n}{obj\PYGZus{}det\PYGZus{}config}\PYG{o}{.}\PYG{n}{networks}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}

  \PYG{c+c1}{\PYGZsh{} Get resolution for a specified network from config.py}
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}get\PYGZus{}resolution}\PYG{p}{(}\PYG{n}{net\PYGZus{}name}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{obj\PYGZus{}det\PYGZus{}config}\PYG{o}{.}\PYG{n}{networks}\PYG{p}{[}\PYG{n}{net\PYGZus{}name}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{k}{class} \PYG{n+nc}{Tools}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Utility class centered around images and filesnames.}
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}
  \PYG{k}{def} \PYG{n+nf}{verify\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}\PYG{p}{:}
      \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Error: file }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fname}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ could not be located.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
      \PYG{k}{return}

  \PYG{k}{def} \PYG{n+nf}{exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n+nb}{bool}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Boolean function to determine if path to filename exists.}

\PYG{l+s+sd}{    :param fname: Path to file.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :rtype: boolean}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{return} \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}mxnet\PYGZus{}image}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given path to an image file, return the said image in the form of an mxnet ndarray.}

\PYG{l+s+sd}{    :param fname: Path to file.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :rtype: mxnet.ndarray.ndarray.NDArray}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{verify\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{mxnet}\PYG{o}{.}\PYG{n}{image}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{get\PYGZus{}cv2\PYGZus{}image}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given path to an image file, return the said image in the form of an numpy ndarray using openCV.}

\PYG{l+s+sd}{    :param fname: Path to file.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :rtype: numpy.ndarray}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{verify\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{cvtColor}\PYG{p}{(}\PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}\PYG{p}{,} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{COLOR\PYGZus{}BGR2RGB}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{show\PYGZus{}image}\PYG{p}{(}\PYG{n}{img}\PYG{p}{:} \PYG{n}{numpy}\PYG{o}{.}\PYG{n}{ndarray}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given an image in the form of an numpy ndarray, show the image to the screen.}

\PYG{l+s+sd}{    :param img: Image in the form of an ndarray.}
\PYG{l+s+sd}{    :type img: numpy.ndarray or mxnet.ndarray.ndarray.NDArray}
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{viz}\PYG{o}{.}\PYG{n}{plot\PYGZus{}image}\PYG{p}{(}\PYG{n}{img}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{filename\PYGZus{}show\PYGZus{}image}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given path to an image file, show the said image file to the screen.}

\PYG{l+s+sd}{    :param fname: Path to image.}
\PYG{l+s+sd}{    :type fname: string}
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{Tools}\PYG{o}{.}\PYG{n}{verify\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{n}{img} \PYG{o}{=} \PYG{n}{mxnet}\PYG{o}{.}\PYG{n}{image}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
    \PYG{n}{gluoncv}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{viz}\PYG{o}{.}\PYG{n}{plot\PYGZus{}image}\PYG{p}{(}\PYG{n}{img}\PYG{p}{)}

  \PYG{k}{def} \PYG{n+nf}{save\PYGZus{}image}\PYG{p}{(}\PYG{n}{img}\PYG{p}{:} \PYG{n}{numpy}\PYG{o}{.}\PYG{n}{ndarray}\PYG{p}{,} \PYG{n}{path}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Given an image in the form of an ndarray, save it to the path specified.}

\PYG{l+s+sd}{    :param img: Image in the form of an ndarray.}
\PYG{l+s+sd}{    :type img: numpy.ndarray or mxnet.ndarray.ndarray.NDArray}
\PYG{l+s+sd}{    :param path: Path to save image to.}
\PYG{l+s+sd}{    :type path: string}
\PYG{l+s+sd}{    :rtype: void}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{img} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{cvtColor}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{COLOR\PYGZus{}BGR2RGB}\PYG{p}{)}
    \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imwrite}\PYG{p}{(}\PYG{n}{path}\PYG{p}{,} \PYG{n}{img}\PYG{p}{)}
    
  \PYG{k}{def} \PYG{n+nf}{\PYGZus{}exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n+nb}{bool}\PYG{p}{:}
    \PYG{k}{if} \PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{exists}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}\PYG{p}{:}
      \PYG{k}{return} \PYG{k+kc}{True}
    \PYG{k}{return} \PYG{k+kc}{False}

\end{sphinxVerbatim}


\paragraph{\_\_init\_\_.py}
\label{\detokenize{comp_viz.utils:init-py}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{.}\PYG{n+nn}{toolbox} \PYG{k+kn}{import} \PYG{o}{*}
\end{sphinxVerbatim}


\subsection{Comp Viz package configuration file}
\label{\detokenize{comp_viz:comp-viz-package-configuration-file}}

\subsection{comp\_viz.config}
\label{\detokenize{comp_viz:module-comp_viz.config}}\label{\detokenize{comp_viz:comp-viz-config}}\index{module@\spxentry{module}!comp\_viz.config@\spxentry{comp\_viz.config}}\index{comp\_viz.config@\spxentry{comp\_viz.config}!module@\spxentry{module}}\index{CompViz (class in comp\_viz.config)@\spxentry{CompViz}\spxextra{class in comp\_viz.config}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz:comp_viz.config.CompViz}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.config.}}\sphinxbfcode{\sphinxupquote{CompViz}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
Most parental configuration class for the comp\_viz package.
\begin{quote}\begin{description}
\sphinxlineitem{Variables}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{version}} \textendash{} Version number for the comp\_viz package.

\end{description}\end{quote}
\index{version (comp\_viz.config.CompViz attribute)@\spxentry{version}\spxextra{comp\_viz.config.CompViz attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz:comp_viz.config.CompViz.version}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{version}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }\textquotesingle{}1.0.0\textquotesingle{}}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{Models (class in comp\_viz.config)@\spxentry{Models}\spxextra{class in comp\_viz.config}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz:comp_viz.config.Models}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.config.}}\sphinxbfcode{\sphinxupquote{Models}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: {\hyperref[\detokenize{comp_viz:comp_viz.config.CompViz}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{CompViz}}}}}

\sphinxAtStartPar
Configuration class for available functionality for the comp\_viz package.
\begin{quote}\begin{description}
\sphinxlineitem{Variables}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{tasks}} \textendash{} List of supported tasks provided by comp\_viz package.

\end{description}\end{quote}
\index{tasks (comp\_viz.config.Models attribute)@\spxentry{tasks}\spxextra{comp\_viz.config.Models attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz:comp_viz.config.Models.tasks}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{tasks}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }{[}\textquotesingle{}Object Detection\textquotesingle{}{]}}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{ObjectDetection (class in comp\_viz.config)@\spxentry{ObjectDetection}\spxextra{class in comp\_viz.config}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz:comp_viz.config.ObjectDetection}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{comp\_viz.config.}}\sphinxbfcode{\sphinxupquote{ObjectDetection}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: {\hyperref[\detokenize{comp_viz:comp_viz.config.CompViz}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{CompViz}}}}}

\sphinxAtStartPar
Configuration class for the object detection task for the comp\_viz package.
\begin{quote}\begin{description}
\sphinxlineitem{Variables}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{networks}} \textendash{} Dictionary of supported networks for object detection for the comp viz package. Each network has an associated inference resolution.

\end{description}\end{quote}
\index{networks (comp\_viz.config.ObjectDetection attribute)@\spxentry{networks}\spxextra{comp\_viz.config.ObjectDetection attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{comp_viz:comp_viz.config.ObjectDetection.networks}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{networks}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }\{\textquotesingle{}center\_net\_resnet101\_v1b\_dcnv2\_coco\textquotesingle{}: \{\textquotesingle{}resolution\textquotesingle{}: 416\}, \textquotesingle{}faster\_rcnn\_fpn\_resnet50\_v1b\_coco\textquotesingle{}: \{\textquotesingle{}resolution\textquotesingle{}: 416\}, \textquotesingle{}faster\_rcnn\_fpn\_syncbn\_resnest269\_coco\textquotesingle{}: \{\textquotesingle{}resolution\textquotesingle{}: 416\}, \textquotesingle{}ssd\_512\_resnet50\_v1\_coco\textquotesingle{}: \{\textquotesingle{}resolution\textquotesingle{}: 416\}, \textquotesingle{}yolo3\_darknet53\_coco\textquotesingle{}: \{\textquotesingle{}resolution\textquotesingle{}: 416\}, \textquotesingle{}yolo3\_mobilenet1.0\_coco\textquotesingle{}: \{\textquotesingle{}resolution\textquotesingle{}: 416\}\}}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}



\subsection{config.py source code}
\label{\detokenize{comp_viz:config-py-source-code}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Author(s): Lucas Hirt}
\PYG{c+c1}{\PYGZsh{} Date Modified: 11/27/2022}

\PYG{k}{class} \PYG{n+nc}{CompViz}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Most parental configuration class for the comp\PYGZus{}viz package.}
\PYG{l+s+sd}{  }
\PYG{l+s+sd}{  :ivar version: Version number for the comp\PYGZus{}viz package.}
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}
  \PYG{n}{version} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1.0.0}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{k}{class} \PYG{n+nc}{Models}\PYG{p}{(}\PYG{n}{CompViz}\PYG{p}{)}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Configuration class for available functionality for the comp\PYGZus{}viz package. }

\PYG{l+s+sd}{  :ivar tasks: List of supported tasks provided by comp\PYGZus{}viz package.}
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}
  \PYG{n}{tasks} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Object Detection}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{k}{class} \PYG{n+nc}{ObjectDetection}\PYG{p}{(}\PYG{n}{CompViz}\PYG{p}{)}\PYG{p}{:}
  \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Configuration class for the object detection task for the comp\PYGZus{}viz package.}

\PYG{l+s+sd}{  :ivar networks: Dictionary of supported networks for object detection for the comp viz package. Each network has an associated inference resolution.}
\PYG{l+s+sd}{  \PYGZdq{}\PYGZdq{}\PYGZdq{}}
  \PYG{n}{networks} \PYG{o}{=} \PYG{p}{\PYGZob{}}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yolo3\PYGZus{}mobilenet1.0\PYGZus{}coco}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{416} \PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yolo3\PYGZus{}darknet53\PYGZus{}coco}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{416} \PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ssd\PYGZus{}512\PYGZus{}resnet50\PYGZus{}v1\PYGZus{}coco}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{416} \PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{center\PYGZus{}net\PYGZus{}resnet101\PYGZus{}v1b\PYGZus{}dcnv2\PYGZus{}coco}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{416} \PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{faster\PYGZus{}rcnn\PYGZus{}fpn\PYGZus{}resnet50\PYGZus{}v1b\PYGZus{}coco}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{416} \PYG{p}{\PYGZcb{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{faster\PYGZus{}rcnn\PYGZus{}fpn\PYGZus{}syncbn\PYGZus{}resnest269\PYGZus{}coco}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{resolution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mi}{416} \PYG{p}{\PYGZcb{}}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{\_\_init\_\_.py source code}
\label{\detokenize{comp_viz:init-py-source-code}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{.} \PYG{k+kn}{import} \PYG{n}{utils}
\PYG{k+kn}{from} \PYG{n+nn}{.} \PYG{k+kn}{import} \PYG{n}{object\PYGZus{}detection}
\end{sphinxVerbatim}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{c}
\item\relax\sphinxstyleindexentry{comp\_viz.config}\sphinxstyleindexpageref{comp_viz:\detokenize{module-comp_viz.config}}
\item\relax\sphinxstyleindexentry{comp\_viz.object\_detection}\sphinxstyleindexpageref{comp_viz.object_detection:\detokenize{module-comp_viz.object_detection}}
\item\relax\sphinxstyleindexentry{comp\_viz.object\_detection.model}\sphinxstyleindexpageref{comp_viz.object_detection:\detokenize{module-comp_viz.object_detection.model}}
\item\relax\sphinxstyleindexentry{comp\_viz.utils}\sphinxstyleindexpageref{comp_viz.utils:\detokenize{module-comp_viz.utils}}
\item\relax\sphinxstyleindexentry{comp\_viz.utils.toolbox}\sphinxstyleindexpageref{comp_viz.utils:\detokenize{module-comp_viz.utils.toolbox}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}